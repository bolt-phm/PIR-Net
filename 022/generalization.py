import os
import json
import torch
import logging
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# å¼•å…¥è‡ªå®šä¹‰æ¨¡å—
from dataset import create_dataloaders
from model import build_model  # ç¡®ä¿ model.py ä¸­çš„ build_model å¯ç”¨

# å¼ºåˆ¶è®¾ç½®æ—¥å¿—ç¼–ç 
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# -------------------------------------------------
#   æ ¸å¿ƒï¼šé›†æˆæ¨¡å‹åŒ…è£…å™¨ (Ensemble Wrapper)
# -------------------------------------------------
class EnsembleModel(torch.nn.Module):
    def __init__(self, config, model_paths, device):
        super().__init__()
        self.models = torch.nn.ModuleList()
        self.device = device
        
        logging.info(f"ğŸŒŸ åˆå§‹åŒ–é›†æˆæ¨¡å‹ï¼Œå…±æœ‰ {len(model_paths)} ä¸ªæˆå‘˜:")
        
        for path in model_paths:
            if not os.path.exists(path):
                logging.warning(f"âš ï¸ æƒé‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {path}")
                continue
                
            # æ„å»ºå•ä½“æ¨¡å‹ç»“æ„
            model = build_model(config).to(device)
            
            # åŠ è½½æƒé‡
            try:
                checkpoint = torch.load(path, map_location=device)
                if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                    model.load_state_dict(checkpoint['model_state_dict'])
                else:
                    model.load_state_dict(checkpoint)
                
                model.eval()
                self.models.append(model)
                logging.info(f"  âœ… å·²åŠ è½½: {os.path.basename(path)}")
            except Exception as e:
                logging.error(f"  âŒ åŠ è½½å¤±è´¥ {path}: {e}")
            
        if len(self.models) == 0:
            raise RuntimeError("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•æœ‰æ•ˆæ¨¡å‹ï¼è¯·æ£€æŸ¥è·¯å¾„ã€‚")

    def forward(self, img, sig):
        # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„è¾“å‡º
        outputs = []
        for model in self.models:
            out = model(img, sig)
            outputs.append(out)
        
        # --- æ ¸å¿ƒé›†æˆç­–ç•¥ï¼šè½¯æŠ•ç¥¨ (Soft Voting) ---
        # 1. å¯¹æ¯ä¸ªæ¨¡å‹çš„è¾“å‡ºåš Softmaxï¼Œå¾—åˆ°æ¦‚ç‡åˆ†å¸ƒ
        probs = [torch.softmax(out, dim=1) for out in outputs]
        
        # 2. å¯¹æ¦‚ç‡å–å¹³å‡
        avg_probs = torch.mean(torch.stack(probs), dim=0)
        
        # 3. è¿”å› Logits (å– Log ä¿æŒæ•°å€¼ç‰¹æ€§å…¼å®¹)
        return torch.log(avg_probs + 1e-8) 

# -------------------------------------------------
#   ä¸»ç¨‹åº
# -------------------------------------------------
def main():
    # 1. é…ç½®åŠ è½½
    config_path = 'config.json'
    if not os.path.exists(config_path):
        logging.error("æœªæ‰¾åˆ° config.json æ–‡ä»¶")
        return

    # ã€ä¿®å¤ 1ã€‘å¼ºåˆ¶ä½¿ç”¨ utf-8 è¯»å–é…ç½®ï¼Œè§£å†³ GBK æŠ¥é”™
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
        
    device = torch.device(config['train']['device'] if torch.cuda.is_available() else 'cpu')
    logging.info(f"Using device: {device}")

    # ================= ã€ä¿®å¤ 2ã€‘å¯¹æ¥ GUI é…ç½® =================
    # ä¼˜å…ˆä» config['inference']['ensemble_models'] è¯»å–åˆ—è¡¨
    # å¦‚æœè¯¥åˆ—è¡¨ä¸ºç©ºï¼Œåˆ™å›é€€åˆ° best_model_name (å•æ¨¡å‹æ¨¡å¼)
    
    ensemble_weights = config.get('inference', {}).get('ensemble_models', [])
    
    # è¿‡æ»¤æ‰ç©ºå­—ç¬¦ä¸²æˆ–æ— æ•ˆè·¯å¾„
    ensemble_weights = [p for p in ensemble_weights if p and os.path.exists(p)]
    
    if not ensemble_weights:
        logging.warning("Config ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„é›†æˆæ¨¡å‹åˆ—è¡¨ï¼Œå›é€€åˆ°é»˜è®¤æœ€ä½³æ¨¡å‹ (Single Model Mode)ã€‚")
        default_path = os.path.join(config['train']['model_dir'], config['train']['best_model_name'])
        ensemble_weights = [default_path]
    else:
        logging.info(f"ä»é…ç½®ä¸­è¯»å–åˆ° {len(ensemble_weights)} ä¸ªé›†æˆæ¨¡å‹è·¯å¾„ã€‚")
    # ========================================================
    
    # 3. åˆå§‹åŒ–é›†æˆæ¨¡å‹
    try:
        model = EnsembleModel(config, ensemble_weights, device)
    except Exception as e:
        logging.error(str(e))
        return

    # 4. åŠ è½½æµ‹è¯•æ•°æ®
    logging.info("Initializing Data Loaders...")
    # åªåŠ è½½æµ‹è¯•é›†
    _, _, test_loaders = create_dataloaders(config)
    
    if not test_loaders:
        logging.error("æµ‹è¯•é›†åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ config ä¸­çš„æ•°æ®è·¯å¾„ã€‚")
        return

    # 5. æ¨ç†è¯„ä¼°
    all_preds = []
    all_labels = []
    
    logging.info("Starting Ensemble Inference on Test Split...")
    
    with torch.no_grad():
        # éå†æ‰€æœ‰æµ‹è¯• DataLoader
        for name, loader in test_loaders.items():
            for batch in tqdm(loader, desc=f"Testing ({name})"):
                # è§£åŒ…æ•°æ® (å…¼å®¹ dataset.py çš„è¿”å›æ ¼å¼)
                if len(batch) == 3:
                    img, sig, lbl = batch
                elif len(batch) == 4:
                    img, sig, lbl, _ = batch
                else:
                    continue

                if img is None: continue
                
                img = img.to(device)
                sig = sig.to(device)
                lbl = lbl.to(device)
                
                # é›†æˆæ¨¡å‹å‰å‘ä¼ æ’­
                output = model(img, sig)
                
                # è·å–é¢„æµ‹ç±»åˆ«
                _, pred = torch.max(output, 1)
                
                all_preds.extend(pred.cpu().numpy())
                all_labels.extend(lbl.cpu().numpy())

    # 6. ç”ŸæˆæŠ¥å‘Š
    acc = accuracy_score(all_labels, all_preds)
    logging.info("="*60)
    logging.info(f"ğŸ”¥ FINAL RESULT ACCURACY: {acc:.4f} (Models: {len(ensemble_weights)})")
    logging.info("="*60)
    
    # è·å–ç±»åˆ«åç§°
    target_names = config['data'].get('case_ids', [str(i) for i in range(config['data']['num_classes'])])
    
    # æ‰“å°è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    report = classification_report(all_labels, all_preds, target_names=target_names, digits=4, zero_division=0)
    print("\nDetailed Classification Report:\n")
    print(report)
    
    # 7. ç»˜åˆ¶å¹¶ä¿å­˜æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(12, 10))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)
    plt.title(f'Confusion Matrix (Acc: {acc:.4f})')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    
    log_dir = config['train']['log_dir']
    os.makedirs(log_dir, exist_ok=True)
    
    # æ³¨æ„ï¼šæ–‡ä»¶åå¿…é¡»ä¸ Form1.cs ä¸­çš„ logImgName ä¿æŒä¸€è‡´
    save_path = os.path.join(log_dir, 'final_generalization_matrix.png')
    plt.savefig(save_path)
    logging.info(f"Confusion Matrix saved to: {save_path}")
    
    # ä¿å­˜è¯¦ç»†æ–‡æœ¬æŠ¥å‘Š
    with open(os.path.join(log_dir, 'ensemble_report.txt'), 'w', encoding='utf-8') as f:
        f.write(f"Ensemble Accuracy: {acc:.4f}\n")
        f.write("Models used:\n")
        for p in ensemble_weights:
            f.write(f"- {p}\n")
        f.write("\n")
        f.write(report)

if __name__ == '__main__':
    main()