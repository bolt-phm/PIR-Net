import os
import json
import torch
import logging
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# å¼•å…¥è‡ªå®šä¹‰æ¨¡å—
from dataset import create_dataloaders
from model import build_model 

# å¼ºåˆ¶è®¾ç½®æ—¥å¿—ç¼–ç 
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# =================================================
#  å·¥å…·å‡½æ•°ï¼šå¼ºåˆ¶å™ªå£°æ³¨å…¥
# =================================================
def inject_awgn_tensor(inputs, snr_db, description="Tensor"):
    """
    inputs: Tensor
    snr_db: float
    description: ç”¨äºæ‰“å°è°ƒè¯•ä¿¡æ¯çš„åå­—
    return: noisy_inputs, debug_info_str
    """
    if snr_db is None:
        return inputs, None
    
    inputs = inputs.float()
    
    # è®¡ç®—ä¿¡å·å¹³å‡åŠŸç‡
    flat_inputs = inputs.view(inputs.size(0), -1)
    signal_power = torch.mean(flat_inputs ** 2, dim=1, keepdim=True) # [N, 1]
    avg_signal_power = torch.mean(signal_power).item() # ä»…ç”¨äºæ‰“å°
    
    # è®¡ç®—å™ªå£°åŠŸç‡
    noise_power = signal_power / (10 ** (snr_db / 10.0))
    avg_noise_power = torch.mean(noise_power).item() # ä»…ç”¨äºæ‰“å°
    
    # ç”Ÿæˆå™ªå£°
    noise = torch.randn_like(inputs)
    
    # è°ƒæ•´å¹…åº¦
    view_shape = [inputs.size(0)] + [1] * (inputs.ndim - 1)
    scale = torch.sqrt(noise_power).view(*view_shape)
    
    noisy_input = inputs + noise * scale
    
    debug_msg = f"[{description}] P_sig:{avg_signal_power:.5f} | P_noise:{avg_noise_power:.5f} (SNR={snr_db})"
    return noisy_input, debug_msg

# -------------------------------------------------
#   é›†æˆæ¨¡å‹åŒ…è£…å™¨ (ä¿æŒä¸å˜)
# -------------------------------------------------
class EnsembleModel(torch.nn.Module):
    def __init__(self, config, model_paths, device):
        super().__init__()
        self.models = torch.nn.ModuleList()
        self.device = device
        logging.info(f"ğŸŒŸ åˆå§‹åŒ–é›†æˆæ¨¡å‹ï¼Œå…±æœ‰ {len(model_paths)} ä¸ªæˆå‘˜:")
        for path in model_paths:
            if not os.path.exists(path):
                continue
            model = build_model(config).to(device)
            try:
                checkpoint = torch.load(path, map_location=device)
                if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                    model.load_state_dict(checkpoint['model_state_dict'])
                else:
                    model.load_state_dict(checkpoint)
                model.eval()
                self.models.append(model)
            except Exception as e:
                logging.error(f"  âŒ åŠ è½½å¤±è´¥ {path}: {e}")
            
        if len(self.models) == 0:
            raise RuntimeError("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•æœ‰æ•ˆæ¨¡å‹ï¼")

    def forward(self, img, sig):
        outputs = []
        for model in self.models:
            out = model(img, sig)
            outputs.append(out)
        probs = [torch.softmax(out, dim=1) for out in outputs]
        avg_probs = torch.mean(torch.stack(probs), dim=0)
        return torch.log(avg_probs + 1e-8) 

# -------------------------------------------------
#   ä¸»ç¨‹åº
# -------------------------------------------------
def main():
    config_path = 'config.json'
    if not os.path.exists(config_path):
        return

    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
        
    device = torch.device(config['train']['device'] if torch.cuda.is_available() else 'cpu')
    
    # æ¨¡å‹åŠ è½½é€»è¾‘
    ensemble_weights = config.get('inference', {}).get('ensemble_models', [])
    ensemble_weights = [p for p in ensemble_weights if p and os.path.exists(p)]
    if not ensemble_weights:
        default_path = os.path.join(config['train']['model_dir'], config['train']['best_model_name'])
        ensemble_weights = [default_path]
    
    try:
        model = EnsembleModel(config, ensemble_weights, device)
    except Exception as e:
        logging.error(str(e))
        return

    logging.info("Initializing Data Loaders...")
    _, _, test_loaders = create_dataloaders(config)
    
    if not test_loaders:
        return

    # ==== è·å–å¼ºåˆ¶ SNR å‚æ•° ====
    forced_snr_str = os.environ.get('FORCE_SNR')
    forced_snr = float(forced_snr_str) if forced_snr_str is not None and forced_snr_str != "" else None
    
    if forced_snr is not None:
        logging.info(f"âš ï¸ [DEBUG] å¼ºåˆ¶å™ªå£°æ³¨å…¥æ¨¡å¼å·²æ¿€æ´»! SNR = {forced_snr} dB")
        logging.info(f"âš ï¸ [DEBUG] å°†åŒæ—¶æ”»å‡» Signal å’Œ Image é€šé“ï¼")

    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for name, loader in test_loaders.items():
            # å¢åŠ ä¸€ä¸ª batch è®¡æ•°å™¨ï¼Œåªåœ¨ç¬¬ä¸€ä¸ª batch æ‰“å°è°ƒè¯•ä¿¡æ¯
            batch_idx = 0
            for batch in tqdm(loader, desc=f"Testing ({name})"):
                if len(batch) == 3:
                    img, sig, lbl = batch
                elif len(batch) == 4:
                    img, sig, lbl, _ = batch
                else:
                    continue

                if img is None: continue
                
                img = img.to(device)
                sig = sig.to(device)
                lbl = lbl.to(device)
                
                # ===========================================
                # ğŸš€ å¼ºåˆ¶æ³¨å…¥å™ªå£° (æ”»å‡»æ‰€æœ‰è¾“å…¥)
                # ===========================================
                if forced_snr is not None:
                    # 1. æ”»å‡» Signal
                    sig, debug_sig = inject_awgn_tensor(sig, forced_snr, "Signal")
                    # 2. æ”»å‡» Image (å‡è®¾ img ä¹Ÿæ˜¯æµ®ç‚¹æ•°ï¼Œå¦‚æœæ˜¯é¢‘è°±å›¾ï¼Œè¿™ç›¸å½“äºåŠ å™ª)
                    img, debug_img = inject_awgn_tensor(img, forced_snr, "Image")
                    
                    # åªæ‰“å°ç¬¬ä¸€ä¸ª batch çš„èƒ½é‡ç»Ÿè®¡ï¼Œè¯æ˜æˆ‘ä»¬çœŸçš„æ”¹äº†æ•°æ®
                    if batch_idx == 0:
                        print(f"\n[DEBUG CHECK] {debug_sig}")
                        print(f"[DEBUG CHECK] {debug_img}")
                        # å†æ¬¡ç¡®è®¤æ•°æ®èŒƒå›´
                        print(f"[DEBUG CHECK] Sig range: {sig.min():.2f} to {sig.max():.2f}")
                        print(f"[DEBUG CHECK] Img range: {img.min():.2f} to {img.max():.2f}\n")
                
                batch_idx += 1
                # ===========================================
                
                output = model(img, sig)
                _, pred = torch.max(output, 1)
                
                all_preds.extend(pred.cpu().numpy())
                all_labels.extend(lbl.cpu().numpy())

    acc = accuracy_score(all_labels, all_preds)
    mode_str = f"SNR={forced_snr}dB" if forced_snr is not None else "Clean"
    logging.info(f"ğŸ”¥ FINAL RESULT ACCURACY: {acc:.4f} [{mode_str}]")
    
    target_names = config['data'].get('case_ids', [str(i) for i in range(config['data']['num_classes'])])
    report = classification_report(all_labels, all_preds, target_names=target_names, digits=4, zero_division=0)
    
    # æ‰“å°ç»“æœï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
    print(f"FINAL RESULT ACCURACY: {acc:.4f}") # ä¾› Launcher è§£æ
    
    # ä¿å­˜ç»“æœ
    log_dir = config['train']['log_dir']
    os.makedirs(log_dir, exist_ok=True)
    filename_suffix = f"_SNR{int(forced_snr)}" if forced_snr is not None else ""
    
    with open(os.path.join(log_dir, f'ensemble_report{filename_suffix}.txt'), 'w', encoding='utf-8') as f:
        f.write(report)

if __name__ == '__main__':
    main()