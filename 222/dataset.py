import os
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
import cv2
import random
import logging
from scipy.signal import stft
import glob
import warnings

# ----------------------------- #
#          é…ç½®ä¸åˆå§‹åŒ–
# ----------------------------- #
warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ----------------------------- #
#       æ ¸å¿ƒä¿¡å·å¤„ç†å¼•æ“
# ----------------------------- #

def add_awgn(signal, target_snr_db):
    """
    ã€æ–°å¢ã€‘ç‰©ç†å±‚çº§çš„é«˜æ–¯ç™½å™ªå£°æ³¨å…¥
    æ ¹æ®ç›®æ ‡ SNR(dB) è®¡ç®—å™ªå£°åŠŸç‡å¹¶å åŠ ã€‚
    å…¬å¼: P_noise = P_signal / 10^(SNR/10)
    """
    signal = signal.astype(np.float32)
    
    # è®¡ç®—ä¿¡å·åŠŸç‡ (Mean Square)
    sig_power = np.mean(signal ** 2)
    
    # é™éŸ³ä¿æŠ¤
    if sig_power == 0:
        return signal
    
    # è®¡ç®—ç›®æ ‡å™ªå£°åŠŸç‡
    noise_power = sig_power / (10 ** (target_snr_db / 10.0))
    
    # ç”Ÿæˆæ ‡å‡†æ­£æ€å™ªå£°å¹¶ç¼©æ”¾
    noise = np.random.randn(*signal.shape).astype(np.float32) * np.sqrt(noise_power)
    
    return signal + noise

def smart_resample(raw_signal, target_len=8192):
    """
    ã€è‡ªé€‚åº”æ™ºèƒ½é‡é‡‡æ ·ã€‘
    ä¸ä¾èµ–å›ºå®š factorï¼Œè€Œæ˜¯æ ¹æ®è¾“å…¥é•¿åº¦è‡ªé€‚åº”è®¡ç®—ã€‚
    ç¡®ä¿æ— è®º Scale æ˜¯ 0.8 è¿˜æ˜¯ 1.2ï¼Œè¾“å‡ºæ°¸è¿œæ˜¯ target_len (8192)ã€‚
    
    ä¿ç•™: 0.7 * Max(è¿‡å†²) + 0.3 * Mean(å°é˜¶)
    """
    input_len = len(raw_signal)
    
    # å¦‚æœæ•°æ®ä¸å¤Ÿé•¿ï¼Œå…ˆå¼ºåˆ¶çº¿æ€§æ’å€¼æ‹‰ä¼¸ (è¿™ç§æƒ…å†µæå°‘è§ï¼Œä½†éœ€å®¹é”™)
    if input_len < target_len:
        return cv2.resize(raw_signal.reshape(1, -1), (target_len, 1)).flatten().astype(np.float32)
        
    # è®¡ç®—è‡ªé€‚åº”é™é‡‡æ ·å› å­
    factor = input_len // target_len
    if factor < 1: factor = 1
    
    # ä¸ºäº†ä¿è¯æ•´é™¤ï¼Œæˆªæ–­å¤šä½™çš„å°¾éƒ¨
    valid_len = target_len * factor
    cropped = raw_signal[:valid_len]
    
    # Reshape è¿›è¡Œæ± åŒ–
    reshaped = cropped.reshape(target_len, factor)
    abs_sig = np.abs(reshaped)
    
    # æ··åˆæ± åŒ–ç­–ç•¥
    peak_hold = np.max(abs_sig, axis=1)
    energy_trend = np.mean(abs_sig, axis=1)
    
    downsampled = 0.7 * peak_hold + 0.3 * energy_trend
    return downsampled.astype(np.float32)

def normalize_robust(x):
    """ 
    ã€æ–°å¢ã€‘é²æ£’å½’ä¸€åŒ– 
    å…ˆè¿›è¡Œ 3-sigma æˆªæ–­ï¼Œå»é™¤æç«¯å™ªå£°å°–å³°ï¼Œå†åš MinMaxã€‚
    é˜²æ­¢å¼ºå™ªå£°ï¼ˆå¦‚ 0dBï¼‰ä¸‹çš„ä¸ªåˆ«æå€¼å¯¼è‡´æ•´ä½“å›¾åƒå˜é»‘ã€‚
    """
    mu = np.mean(x)
    std = np.std(x)
    
    # æˆªæ–­åŒºé—´ [mu - 3std, mu + 3std]
    lower, upper = mu - 3 * std, mu + 3 * std
    x = np.clip(x, lower, upper)
    
    # æ ‡å‡† MinMax
    mi, ma = np.min(x), np.max(x)
    if ma - mi > 1e-8:
        return (x - mi) / (ma - mi)
    return x.astype(np.float32)

def normalize_minmax(x):
    """ ä¼ ç»Ÿå½’ä¸€åŒ– (ä¿ç•™ç”¨äºéæ•æ„Ÿæ•°æ®) """
    mi, ma = np.min(x), np.max(x)
    if ma - mi > 1e-8:
        return (x - mi) / (ma - mi)
    return x.astype(np.float32)

def generate_pseudo_image(signal, config):
    """ ç”Ÿæˆ 5 é€šé“é«˜åˆ†è¾¨ç‡ STFT ç‰¹å¾å›¾ """
    if not isinstance(signal, np.ndarray): signal = np.array(signal)
    h, w = tuple(config['data'].get('image_size', [224, 224]))
    
    # é«˜åˆ†è¾¨ç‡é…ç½® (nperseg=256)
    nperseg = 256  
    noverlap = int(nperseg * 0.9) 
    
    channels = []
    try:
        # 1. STFT å¹…åº¦è°±
        _, _, Zxx = stft(signal, fs=10000, nperseg=nperseg, noverlap=noverlap)
        S_db = 20 * np.log10(np.abs(Zxx) + 1e-6)
        # ä½¿ç”¨é²æ£’å½’ä¸€åŒ–
        base_img = cv2.resize(normalize_robust(S_db), (w, h))
        channels.append(base_img)
        
        # 2. æ¢¯åº¦ç‰¹å¾ (æ•æ‰è¾¹ç¼˜)
        grad_f = np.abs(np.gradient(base_img, axis=0))
        grad_t = np.abs(np.gradient(base_img, axis=1))
        channels.append(normalize_robust(grad_f))
        channels.append(normalize_robust(grad_t))
        
        # 3. èƒ½é‡ç‰¹å¾
        channels.append(normalize_robust(base_img ** 2))
        
        # 4. æ—¶åŸŸæ³¢å½¢å¯è§†åŒ–
        time_view = cv2.resize(signal.reshape(1, -1), (w, h))
        channels.append(normalize_robust(time_view))
        
    except Exception:
        # å®¹é”™ï¼šå…¨é»‘å›¾
        return np.zeros((h, w, 5), dtype=np.float32)

    return np.stack(channels, axis=-1).astype(np.float32)

def augment_online(img, sig, config):
    """ 
    è®­ç»ƒæ—¶æ•°æ®å¢å¼º 
    ã€ä¿®æ”¹ã€‘ç§»é™¤äº†æ—§çš„ noise æ·»åŠ é€»è¾‘ï¼Œç»Ÿä¸€åœ¨ __getitem__ ä¸­å¤„ç† SNR å™ªå£°
    """
    aug_cfg = config.get('augment', {})
    sig_cfg = aug_cfg.get('signal', {}).get('params', {})
    img_cfg = aug_cfg.get('image', {})

    # 1. ä¿¡å·å¹…åº¦ç¼©æ”¾ (ä¸æ”¹å˜ SNRï¼Œåªæ”¹å˜å¢ç›Š)
    if random.random() < sig_cfg.get('amplitude_scale_p', 0.5):
        scale = random.uniform(*sig_cfg.get('amplitude_scale_range', [0.8, 1.2]))
        sig = sig * scale

    # 2. ä¿¡å·éšæœºé®æŒ¡ (æ¨¡æ‹Ÿä¸¢åŒ…)
    if random.random() < sig_cfg.get('random_cutout_p', 0.0):
        cut_len = int(len(sig) * 0.1)
        if len(sig) > cut_len:
            start = random.randint(0, len(sig) - cut_len)
            sig[start:start+cut_len] = 0.0

    # 3. å›¾åƒé¢œè‰²æŠ–åŠ¨ (äº®åº¦/å¯¹æ¯”åº¦)
    if random.random() < img_cfg.get('color_jitter_p', 0.0):
        if random.random() < 0.5:
            # äº®åº¦
            img = img + random.uniform(-img_cfg.get('brightness', 0.1), img_cfg.get('brightness', 0.1))
        if random.random() < 0.5:
            # å¯¹æ¯”åº¦
            alpha = random.uniform(1.0 - img_cfg.get('contrast', 0.1), 1.0 + img_cfg.get('contrast', 0.1))
            img = img * alpha
        img = np.clip(img, 0, 1)

    # 4. å›¾åƒéšæœºæ“¦é™¤ (æ¨¡æ‹Ÿå±€éƒ¨é¢‘è°±ä¸¢å¤±)
    if random.random() < img_cfg.get('random_erasing_p', 0.0):
        h, w, c = img.shape
        area_ratio = random.uniform(*img_cfg.get('erasing_area_range', [0.02, 0.1]))
        target_area = h * w * area_ratio
        aspect_ratio = random.uniform(*img_cfg.get('erasing_ratio_range', [0.3, 3.3]))
        
        eh = int(round(np.sqrt(target_area * aspect_ratio)))
        ew = int(round(np.sqrt(target_area / aspect_ratio)))
        
        if eh < h and ew < w:
            y = random.randint(0, h - eh)
            x = random.randint(0, w - ew)
            img[y:y+eh, x:x+ew, :] = 0.0

    return img.astype(np.float32), sig.astype(np.float32)


# ----------------------------- #
#       æ•°æ®é›†æ ¸å¿ƒç±»
# ----------------------------- #

class SmartResampledDataset(Dataset):
    def __init__(self, config, split='train', return_meta=False):
        self.config = config
        self.split = split
        self.is_train = (split == 'train')
        self.return_meta = return_meta
        
        # åŸºç¡€å‚æ•°
        # 1.0 å°ºåº¦ä¸‹çš„åŸå§‹é•¿åº¦ = 8192 * 150 = 1,228,800
        self.base_resample_factor = 150
        self.target_len_resampled = 8192 
        self.base_raw_len = self.target_len_resampled * self.base_resample_factor
        
        self.noise_threshold = 0.1 
        
        # å¤šå°ºåº¦é…ç½®: é»˜è®¤ä¸º [1.0]
        self.scales = config['data'].get('scales', [1.0])
        
        # æ‰«ææ•°æ®ï¼ˆå«ç™½åå•è¿‡æ»¤é€»è¾‘ï¼‰
        self.indices = self._scan_and_index_segments()
        
        if self.is_train:
            random.shuffle(self.indices)
            
        logging.info(f"[{split.upper()}] MultiScale={self.scales}: Indexed {len(self.indices)} segments.")

    def _scan_and_index_segments(self):
        """ 
        æ”¯æŒ Fusion Map + Multi-Scale + Time Splitting + ã€ç™½åå•è¿‡æ»¤ã€‘
        """
        indices = []
        data_dir = self.config['data']['data_dir']
        
        # 1. è·¯å¾„ä¸æ ‡ç­¾è§£æ
        fusion_map = self.config['data'].get('fusion_map', None)
        if fusion_map:
            target_folders = list(fusion_map.keys())
            label_map = fusion_map
        else:
            target_folders = self.config['data']['case_ids']
            label_map = {cid: i for i, cid in enumerate(target_folders)}

        # ã€æ–°å¢ã€‘ç™½åå•é€»è¾‘åˆå§‹åŒ–
        use_whitelist = self.config['data'].get('use_whitelist', False)
        whitelist = set(self.config['data'].get('whitelist', [])) 

        # 2. åˆ‡åˆ†å‚æ•°
        split_ratio = self.config['data'].get('split_ratio', [0.7, 0.15, 0.15])
        overlap_ratio = self.config['data'].get('step_ratio', 0.1) 
        
        # åŸºç¡€æ­¥é•¿ (1.0å°ºåº¦ä¸‹)
        base_step_raw = int(self.base_raw_len * overlap_ratio)
        
        for folder_name in target_folders:
            c_path = os.path.join(data_dir, folder_name)
            if not os.path.exists(c_path): continue
            
            current_label = label_map[folder_name]
            files = sorted(glob.glob(os.path.join(c_path, "*.npy")))
            
            for f_path in files:
                # ç™½åå•è¿‡æ»¤
                if use_whitelist:
                    file_name = os.path.basename(f_path)
                    if file_name not in whitelist:
                        continue

                try:
                    raw_file_ref = np.load(f_path, mmap_mode='r')
                    total_len = len(raw_file_ref)
                    
                    train_end = int(total_len * split_ratio[0])
                    val_end = int(total_len * (split_ratio[0] + split_ratio[1]))
                    
                    if self.split == 'train':
                        start_idx, end_idx = 0, train_end
                    elif self.split == 'val':
                        start_idx, end_idx = train_end, val_end
                    else:
                        start_idx, end_idx = val_end, total_len
                    
                    # å¤šå°ºåº¦å¾ªç¯
                    for scale in self.scales:
                        current_win_len = int(self.base_raw_len * scale)
                        current_step = int(current_win_len * overlap_ratio)
                        
                        if end_idx - start_idx < current_win_len: continue
                        
                        current_ptr = start_idx
                        while current_ptr + current_win_len <= end_idx:
                            indices.append({
                                'path': f_path,
                                'offset': current_ptr,
                                'label': current_label,
                                'scale': scale,          
                                'raw_len': current_win_len
                            })
                            current_ptr += current_step
                        
                except Exception as e:
                    logging.warning(f"Error scanning {f_path}: {e}")
                    continue
                
        return indices

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        meta = self.indices[idx]
        try:
            # 1. ç²¾ç¡®è¯»å–åŸå§‹æ•°æ®
            raw_file = np.load(meta['path'], mmap_mode='r')
            raw_len = meta['raw_len']
            offset = meta['offset']
            
            raw_chunk = raw_file[offset : offset + raw_len]
            raw_chunk = np.array(raw_chunk)
            
            # 2. è‡ªé€‚åº”æ™ºèƒ½é‡é‡‡æ · -> 8192 ç‚¹
            sig = smart_resample(raw_chunk, target_len=self.target_len_resampled)
            
            # 3. å…¨å±€å½’ä¸€åŒ–
            global_scale = self.config['data'].get('global_scale', 1.0)
            sig = sig - np.mean(sig)
            sig = sig / (global_scale + 1e-6)
            
            # ========================================================
            # ğŸš€ æ ¸å¿ƒä¿®æ”¹ï¼šåœ¨ç”Ÿæˆå›¾åƒä¹‹å‰ï¼Œä»æºå¤´æ³¨å…¥ç‰©ç†å™ªå£° (SNR)
            # ========================================================
            
            # è¯»å–é…ç½®
            aug_cfg = self.config.get('augment', {}).get('signal', {})
            aug_params = aug_cfg.get('params', {})
            use_aug = aug_cfg.get('use_augment', False)

            # A. è®­ç»ƒæ¨¡å¼ï¼šéšæœºæ³¨å…¥å™ªå£° (Robust Training)
            if self.is_train and use_aug:
                # æ£€æŸ¥æ¦‚ç‡
                if random.random() < aug_params.get('noise_p', 0.0):
                    # è·å–åˆ†è´èŒƒå›´
                    min_snr = aug_params.get('min_snr_db', -5.0)
                    max_snr = aug_params.get('max_snr_db', 25.0)
                    # éšæœºé€‰æ‹© SNR
                    target_snr = random.uniform(min_snr, max_snr)
                    sig = add_awgn(sig, target_snr)

            # B. éè®­ç»ƒæ¨¡å¼ (Val/Test)ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å¼ºåˆ¶æµ‹è¯•æŒ‡ä»¤
            elif not self.is_train:
                forced_snr_str = os.environ.get('FORCE_SNR')
                if forced_snr_str is not None and forced_snr_str.strip() != "":
                    try:
                        snr_val = float(forced_snr_str)
                        sig = add_awgn(sig, snr_val)
                    except ValueError:
                        pass
            
            # ========================================================

            # 4. ç”Ÿæˆå›¾åƒ
            # æ­¤æ—¶ sig å·²å¸¦å™ªï¼ŒSTFT ä¼šè‡ªåŠ¨å°†å™ªå£°è½¬æ¢ä¸ºé¢‘åŸŸç‰¹å¾
            # generate_pseudo_image å†…éƒ¨å·²æ›´æ–°ä¸º normalize_robust
            img = generate_pseudo_image(sig, self.config)
            
            # 5. å…¶ä»–å¢å¼º (è®­ç»ƒæ—¶å åŠ  Cutout, ColorJitter ç­‰)
            if self.is_train:
                img, sig = augment_online(img, sig, self.config)
            
            img_t = torch.from_numpy(img.transpose(2, 0, 1)).float()
            sig_t = torch.tensor(sig).float().unsqueeze(0)
            
            if self.return_meta:
                meta_info = f"{os.path.basename(meta['path'])}_{meta['offset']}_S{meta['scale']}"
                return img_t, sig_t, meta['label'], meta_info
            
            return img_t, sig_t, meta['label']
            
        except Exception as e:
            # è°ƒè¯•æ—¶å¯è§£å¼€ä¸‹é¢æ³¨é‡Š
            # logging.error(f"Error loading {meta['path']}: {e}")
            return None

# ----------------------------- #
#       DataLoader å·¥å‚
# ----------------------------- #

def pad_collate(batch):
    batch = [b for b in batch if b is not None]
    if not batch: return None
    
    elem_len = len(batch[0])
    imgs = torch.stack([x[0] for x in batch])
    sigs = torch.stack([x[1] for x in batch])
    lbls = torch.tensor([x[2] for x in batch], dtype=torch.long)
    
    if elem_len == 4:
        metas = [x[3] for x in batch]
        return imgs, sigs, lbls, metas
    
    return imgs, sigs, lbls

def create_dataloaders(config, return_meta=False):
    loaders = {}
    loader_key = "SmartResample_F150"
    
    for split in ['train', 'val', 'test']:
        ds = SmartResampledDataset(config, split=split, return_meta=return_meta)
        
        if len(ds) > 0:
            loaders[split] = {
                loader_key: DataLoader(
                    ds,
                    batch_size=config['data']['batch_size'],
                    shuffle=(split == 'train'), 
                    num_workers=config['data']['num_workers'],
                    collate_fn=pad_collate,
                    pin_memory=True,
                    persistent_workers=True
                )
            }
        else:
            loaders[split] = {}
            
    return loaders['train'], loaders['val'], loaders['test']

def run_offline_preprocessing(config): pass